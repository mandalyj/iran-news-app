import requests
import pandas as pd
from datetime import datetime, timedelta
import time
import logging
import streamlit as st
import base64
from io import BytesIO
import json
import os
from bs4 import BeautifulSoupÂ  # For extracting article content

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configuration - API keys are fetched from environment variables
GNEWS_API_URL = "https://gnews.io/api/v4/search"
GNEWS_API_KEY = os.environ.get("GNEWS_API_KEY", "YOUR_GNEWS_API_KEY")
WORLDNEWS_API_URL = "https://api.worldnewsapi.com/search-news"
WORLDNEWS_API_KEY = os.environ.get("WORLDNEWS_API_KEY", "YOUR_WORLDNEWS_API_KEY")
COINGECKO_API_URL = "https://api.coingecko.com/api/v3"
FMP_API_URL = "https://financialmodelingprep.com/api/v3"
FMP_API_KEY = os.environ.get("FMP_API_KEY", "YOUR_FMP_API_KEY")
AVALAI_API_URL_DEFAULT = "https://api.avalai.ir/v1"
AVALAI_API_KEY = os.environ.get("AVALAI_API_KEY", "YOUR_AVALAI_API_KEY")

TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN", "YOUR_TELEGRAM_BOT_TOKEN")
TELEGRAM_API_URL = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}"

# Temporary file to store articles/reports and chat IDs
TEMP_FILE = "/tmp/iran_news_articles.json"
CHAT_IDS_FILE = "/tmp/iran_news_chat_ids.json"

# Initialize Streamlit page with custom CSS
st.set_page_config(
Â  Â  page_title="Iran News Aggregator",
Â  Â  page_icon="ğŸ“°",
Â  Â  layout="wide"
)

# Add custom CSS to adjust text alignment, font, and size
st.markdown(
Â  Â  """
Â  Â  <style>
Â  Â  .persian-text {
Â  Â  Â  Â  direction: rtl;
Â  Â  Â  Â  text-align: right;
Â  Â  Â  Â  font-family: "B Nazanin", "Arial Unicode MS", "Tahoma", sans-serif;
Â  Â  Â  Â  font-size: 16px !important;
Â  Â  }
Â  Â  .english-text {
Â  Â  Â  Â  direction: ltr;
Â  Â  Â  Â  text-align: left;
Â  Â  Â  Â  font-size: 14px !important;
Â  Â  }
Â  Â  .article-section {
Â  Â  Â  Â  margin-bottom: 20px;
Â  Â  Â  Â  padding: 0px;
Â  Â  Â  Â  background-color: #f9f9f9;
Â  Â  }
Â  Â  .report-section {
Â  Â  Â  Â  margin-bottom: 20px;
Â  Â  Â  Â  padding: 10px;
Â  Â  Â  Â  background-color: #e6f3ff;
Â  Â  Â  Â  border-radius: 5px;
Â  Â  }
Â  Â  .neon-line-top {
Â  Â  Â  Â  height: 4px;
Â  Â  Â  Â  background: linear-gradient(90deg, rgba(255, 0, 0, 0.8), rgba(255, 100, 100, 0.8), rgba(255, 0, 0, 0.8));
Â  Â  Â  Â  box-shadow: 0 0 10px rgba(255, 0, 0, 0.7), 0 0 20px rgba(255, 0, 0, 0.5), 0 0 30px rgba(255, 100, 100, 0.3);
Â  Â  Â  Â  margin: 10px 0;
Â  Â  }
Â  Â  .title-link {
Â  Â  Â  Â  font-size: 20px !important;
Â  Â  Â  Â  font-weight: bold !important;
Â  Â  Â  Â  color: #1a73e8 !important;
Â  Â  Â  Â  margin-bottom: 2px !important;
Â  Â  Â  Â  direction: rtl !important;
Â  Â  Â  Â  text-decoration: none !important;
Â  Â  Â  Â  font-family: "B Nazanin", "B Lotus", "Arial Unicode MS", sans-serif !important;
Â  Â  }
Â  Â  .source-date {
Â  Â  Â  Â  font-size: 14px !important;
Â  Â  Â  Â  color: #555 !important;
Â  Â  Â  Â  margin-bottom: 10px !important;
Â  Â  }
Â  Â  .description {
Â  Â  Â  Â  margin-top: 10px !important;
Â  Â  Â  Â  line-height: 1.5 !important;
Â  Â  }
Â  Â  </style>
Â  Â  """,
Â  Â  unsafe_allow_html=True
)

# Function to send error email (disabled as per user request)
def send_error_email(error_message):
Â  Â  logger.info(f"Error email sending is disabled. Error message: {error_message}")

# Load articles/reports from temp file if exists
def load_articles_from_file():
Â  Â  try:
Â  Â  Â  Â  if os.path.exists(TEMP_FILE):
Â  Â  Â  Â  Â  Â  with open(TEMP_FILE, "r") as f:
Â  Â  Â  Â  Â  Â  Â  Â  return json.load(f)
Â  Â  Â  Â  return []
Â  Â  except Exception as e:
Â  Â  Â  Â  logger.warning(f"Error loading articles from file: {str(e)}")
Â  Â  Â  Â  send_error_email(f"Error loading articles from file: {str(e)}")
Â  Â  Â  Â  return []

# Save articles/reports to temp file
def save_articles_to_file(articles):
Â  Â  try:
Â  Â  Â  Â  with open(TEMP_FILE, "w") as f:
Â  Â  Â  Â  Â  Â  json.dump(articles, f)
Â  Â  except Exception as e:
Â  Â  Â  Â  logger.warning(f"Error saving articles to file: {str(e)}")
Â  Â  Â  Â  send_error_email(f"Error saving articles to file: {str(e)}")

# Load chat IDs from file
def load_chat_ids():
Â  Â  try:
Â  Â  Â  Â  if os.path.exists(CHAT_IDS_FILE):
Â  Â  Â  Â  Â  Â  with open(CHAT_IDS_FILE, "r") as f:
Â  Â  Â  Â  Â  Â  Â  Â  return json.load(f)
Â  Â  Â  Â  return {}
Â  Â  except Exception as e:
Â  Â  Â  Â  logger.warning(f"Error loading chat IDs from file: {str(e)}")
Â  Â  Â  Â  send_error_email(f"Error loading chat IDs from file: {str(e)}")
Â  Â  Â  Â  return {}

# Save chat IDs to file
def save_chat_ids(chat_ids):
Â  Â  try:
Â  Â  Â  Â  with open(CHAT_IDS_FILE, "w") as f:
Â  Â  Â  Â  Â  Â  json.dump(chat_ids, f)
Â  Â  except Exception as e:
Â  Â  Â  Â  logger.warning(f"Error saving chat IDs from file: {str(e)}")
Â  Â  Â  Â  send_error_email(f"Error saving chat IDs from file: {str(e)}")

# Fetch news from GNews API
def fetch_gnews(query="Iran", max_records=20, from_date=None, to_date=None):
Â  Â  if not GNEWS_API_KEY or GNEWS_API_KEY == "YOUR_GNEWS_API_KEY":
Â  Â  Â  Â  error_msg = "Invalid GNews API key. Please set a valid API key in Render environment variables."
Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  return [], error_msg

Â  Â  params = {
Â  Â  Â  Â  "q": query,
Â  Â  Â  Â  "apikey": GNEWS_API_KEY,
Â  Â  Â  Â  "lang": "en",
Â  Â  Â  Â  "country": "us",
Â  Â  Â  Â  "max": min(max_records, 100),
Â  Â  Â  Â  "from": from_date,
Â  Â  Â  Â  "to": to_date
Â  Â  }
Â  Â  headers = {
Â  Â  Â  Â  "User-Agent": f"IranNewsAggregator/1.0 (Contact: avestaparsavic@gmail.com)"
Â  Â  }
Â  Â  logger.info(f"Sending GNews request with params: {params}")

Â  Â  try:
Â  Â  Â  Â  response = requests.get(GNEWS_API_URL, params=params, headers=headers, timeout=15)
Â  Â  Â  Â  response.raise_for_status()
Â  Â  Â  Â  data = response.json()
Â  Â  Â  Â  logger.info(f"GNews response: {data}")

Â  Â  Â  Â  if "errors" in data:
Â  Â  Â  Â  Â  Â  error_msg = f"GNews API error: {data['errors']}"
Â  Â  Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  Â  Â  return [], error_msg

Â  Â  Â  Â  articles = data.get("articles", [])
Â  Â  Â  Â  if not articles:
Â  Â  Â  Â  Â  Â  error_msg = f"No articles found for query '{query}' in GNews."
Â  Â  Â  Â  Â  Â  logger.warning(error_msg)
Â  Â  Â  Â  Â  Â  return [], error_msg

Â  Â  Â  Â  return [
Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  "title": a.get("title", "No title"),
Â  Â  Â  Â  Â  Â  Â  Â  "url": a.get("url", ""),
Â  Â  Â  Â  Â  Â  Â  Â  "source": a.get("source", {}).get("name", "Unknown Source"),
Â  Â  Â  Â  Â  Â  Â  Â  "published_at": a.get("publishedAt", ""),
Â  Â  Â  Â  Â  Â  Â  Â  "description": a.get("description", "") or "No description available",
Â  Â  Â  Â  Â  Â  Â  Â  "image_url": a.get("image", ""),
Â  Â  Â  Â  Â  Â  Â  Â  "translated_title": "",
Â  Â  Â  Â  Â  Â  Â  Â  "translated_description": "",
Â  Â  Â  Â  Â  Â  Â  Â  "type": "news"
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  for a in articles
Â  Â  Â  Â  ], None
Â  Â  except Exception as e:
Â  Â  Â  Â  error_msg = f"Error fetching GNews: {str(e)}"
Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  return [], error_msg

# Fetch news from World News API
def fetch_worldnews(query="Iran", max_records=20, from_date=None, to_date=None):
Â  Â  if not WORLDNEWS_API_KEY or WORLDNEWS_API_KEY == "YOUR_WORLDNEWS_API_KEY":
Â  Â  Â  Â  error_msg = "Invalid World News API key. Please set a valid API key in Render environment variables."
Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  return [], error_msg

Â  Â  params = {
Â  Â  Â  Â  "text": query,
Â  Â  Â  Â  "api-key": WORLDNEWS_API_KEY,
Â  Â  Â  Â  "language": "en",
Â  Â  Â  Â  "number": min(max_records, 100),
Â  Â  Â  Â  "sort": "publish-time",
Â  Â  Â  Â  "sort-direction": "DESC",
Â  Â  Â  Â  "start-date": from_date,
Â  Â  Â  Â  "end-date": to_date
Â  Â  }
Â  Â  headers = {
Â  Â  Â  Â  "User-Agent": f"IranNewsAggregator/1.0 (Contact: avestaparsavic@gmail.com)"
Â  Â  }
Â  Â  logger.info(f"Sending World News API request with params: {params}")

Â  Â  try:
Â  Â  Â  Â  response = requests.get(WORLDNEWS_API_URL, params=params, headers=headers, timeout=15)
Â  Â  Â  Â  response.raise_for_status()
Â  Â  Â  Â  data = response.json()
Â  Â  Â  Â  logger.info(f"World News API response: {data}")

Â  Â  Â  Â  if "error" in data:
Â  Â  Â  Â  Â  Â  error_msg = f"World News API error: {data.get('error', 'Unknown error')}"
Â  Â  Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  Â  Â  return [], error_msg

Â  Â  Â  Â  articles = data.get("news", [])
Â  Â  Â  Â  if not articles:
Â  Â  Â  Â  Â  Â  error_msg = f"No articles found for query '{query}' in World News API."
Â  Â  Â  Â  Â  Â  logger.warning(error_msg)
Â  Â  Â  Â  Â  Â  return [], error_msg

Â  Â  Â  Â  return [
Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  "title": a.get("title", "No title"),
Â  Â  Â  Â  Â  Â  Â  Â  "url": a.get("url", ""),
Â  Â  Â  Â  Â  Â  Â  Â  "source": a.get("source", "Unknown Source"),
Â  Â  Â  Â  Â  Â  Â  Â  "published_at": a.get("publish_date", ""),
Â  Â  Â  Â  Â  Â  Â  Â  "description": a.get("text", "") or "No description available",
Â  Â  Â  Â  Â  Â  Â  Â  "image_url": a.get("image", ""),
Â  Â  Â  Â  Â  Â  Â  Â  "translated_title": "",
Â  Â  Â  Â  Â  Â  Â  Â  "translated_description": "",
Â  Â  Â  Â  Â  Â  Â  Â  "type": "news"
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  for a in articles
Â  Â  Â  Â  ], None
Â  Â  except Exception as e:
Â  Â  Â  Â  error_msg = f"Error fetching World News API: {str(e)}"
Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  return [], error_msg

# Fetch crypto news from CoinGecko API with delay and retry
def fetch_coingecko_news(query="cryptocurrency", max_records=20, from_date=None, to_date=None):
Â  Â  endpoint = f"{COINGECKO_API_URL}/news"
Â  Â  headers = {
Â  Â  Â  Â  "User-Agent": f"IranNewsAggregator/1.0 (Contact: avestaparsavic@gmail.com)"
Â  Â  }
Â  Â  params = {
Â  Â  Â  Â  "limit": min(max_records, 100),
Â  Â  }
Â  Â  logger.info(f"Sending CoinGecko news request with params: {params}")

Â  Â  retries = 3
Â  Â  delay = 5
Â  Â  for attempt in range(retries):
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  logger.info(f"Adding a {delay}-second delay before CoinGecko request (Attempt {attempt + 1}/{retries}) to avoid rate limiting...")
Â  Â  Â  Â  Â  Â  time.sleep(delay)

Â  Â  Â  Â  Â  Â  response = requests.get(endpoint, params=params, headers=headers, timeout=15)
Â  Â  Â  Â  Â  Â  response.raise_for_status()
Â  Â  Â  Â  Â  Â  data = response.json()
Â  Â  Â  Â  Â  Â  logger.info(f"CoinGecko news response: {data}")

Â  Â  Â  Â  Â  Â  articles = data.get("data", [])
Â  Â  Â  Â  Â  Â  if not articles:
Â  Â  Â  Â  Â  Â  Â  Â  error_msg = f"No articles found for query '{query}' in CoinGecko."
Â  Â  Â  Â  Â  Â  Â  Â  logger.warning(error_msg)
Â  Â  Â  Â  Â  Â  Â  Â  return [], error_msg

Â  Â  Â  Â  Â  Â  formatted_articles = []
Â  Â  Â  Â  Â  Â  for a in articles:
Â  Â  Â  Â  Â  Â  Â  Â  published_at = a.get("published_at", "")
Â  Â  Â  Â  Â  Â  Â  Â  if from_date and to_date:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  article_date = parse_to_tehran_time(published_at)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not article_date:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  start_datetime = datetime.strptime(from_date, "%Y-%m-%d")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  end_datetime = datetime.strptime(to_date, "%Y-%m-%d")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Adjusting for timezone difference for date comparison
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  start_datetime_tehran = start_datetime - timedelta(hours=3, minutes=30)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  end_datetime_tehran = end_datetime - timedelta(hours=3, minutes=30) + timedelta(days=1) # Include the whole end day

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not (start_datetime_tehran <= article_date <= end_datetime_tehran):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  Â  Â  formatted_articles.append({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "title": a.get("title", "No title"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "url": a.get("url", ""),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "source": a.get("source", "CoinGecko"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "published_at": published_at,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "description": a.get("description", "") or "No description available",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "image_url": a.get("thumb", ""),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "translated_title": "",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "translated_description": "",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "type": "news"
Â  Â  Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â  return formatted_articles, None
Â  Â  Â  Â  except requests.exceptions.HTTPError as e:
Â  Â  Â  Â  Â  Â  if e.response.status_code == 429:
Â  Â  Â  Â  Â  Â  Â  Â  logger.warning(f"Rate limit exceeded (429), retrying in {delay} seconds... (Attempt {attempt + 1}/{retries})")
Â  Â  Â  Â  Â  Â  Â  Â  if attempt < retries - 1:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  time.sleep(delay)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  delay *= 2
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  error_msg = "Max retries exceeded for CoinGecko news due to rate limiting."
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return [], error_msg
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  error_msg = f"Error fetching CoinGecko news: {str(e)}"
Â  Â  Â  Â  Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  Â  Â  Â  Â  return [], error_msg
Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  error_msg = f"Error fetching CoinGecko news: {str(e)}"
Â  Â  Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  Â  Â  return [], error_msg
Â  Â  # Fallback if all retries fail
Â  Â  error_msg = "Failed to fetch CoinGecko news after multiple retries."
Â  Â  logger.error(error_msg)
Â  Â  send_error_email(error_msg)
Â  Â  return [], error_msg


# Fetch financial report from Financial Modeling Prep API
def fetch_financial_report(symbol, max_records=1, from_date=None, to_date=None):
Â  Â  if not FMP_API_KEY or FMP_API_KEY == "YOUR_FMP_API_KEY":
Â  Â  Â  Â  error_msg = "Invalid Financial Modeling Prep API key. Please set a valid API key in Render environment variables."
Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  return [], error_msg

Â  Â  endpoint = f"{FMP_API_URL}/income-statement/{symbol}"
Â  Â  headers = {
Â  Â  Â  Â  "User-Agent": f"IranNewsAggregator/1.0 (Contact: avestaparsavic@gmail.com)",
Â  Â  Â  Â  "Content-Type": "application/json"
Â  Â  }
Â  Â  params = {
Â  Â  Â  Â  "limit": max_records,
Â  Â  Â  Â  "apikey": FMP_API_KEY
Â  Â  }
Â  Â  logger.info(f"Sending Financial Modeling Prep request for symbol {symbol} with params: {params}")

Â  Â  try:
Â  Â  Â  Â  response = requests.get(endpoint, params=params, headers=headers, timeout=15)
Â  Â  Â  Â  response.raise_for_status()
Â  Â  Â  Â  data = response.json()
Â  Â  Â  Â  logger.info(f"Financial Modeling Prep response: {data}")

Â  Â  Â  Â  if not isinstance(data, list):
Â  Â  Â  Â  Â  Â  error_msg = f"Unexpected response format from Financial Modeling Prep: {data}"
Â  Â  Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  Â  Â  return [], error_msg

Â  Â  Â  Â  if not data:
Â  Â  Â  Â  Â  Â  error_msg = f"No financial reports found for symbol '{symbol}'."
Â  Â  Â  Â  Â  Â  logger.warning(error_msg)
Â  Â  Â  Â  Â  Â  return [], error_msg

Â  Â  Â  Â  reports = []
Â  Â  Â  Â  for report in data:
Â  Â  Â  Â  Â  Â  report_date = report.get("date", "")
Â  Â  Â  Â  Â  Â  if from_date and to_date:
Â  Â  Â  Â  Â  Â  Â  Â  report_datetime = datetime.strptime(report_date, "%Y-%m-%d")
Â  Â  Â  Â  Â  Â  Â  Â  start_datetime = datetime.strptime(from_date, "%Y-%m-%d")
Â  Â  Â  Â  Â  Â  Â  Â  end_datetime = datetime.strptime(to_date, "%Y-%m-%d")
Â  Â  Â  Â  Â  Â  Â  Â  if not (start_datetime <= report_datetime <= end_datetime):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  reports.append({
Â  Â  Â  Â  Â  Â  Â  Â  "symbol": report.get("symbol", symbol),
Â  Â  Â  Â  Â  Â  Â  Â  "date": report_date,
Â  Â  Â  Â  Â  Â  Â  Â  "revenue": report.get("revenue", 0),
Â  Â  Â  Â  Â  Â  Â  Â  "netIncome": report.get("netIncome", 0),
Â  Â  Â  Â  Â  Â  Â  Â  "eps": report.get("eps", 0),
Â  Â  Â  Â  Â  Â  Â  Â  "grossProfit": report.get("grossProfit", 0),
Â  Â  Â  Â  Â  Â  Â  Â  "operatingIncome": report.get("operatingIncome", 0),
Â  Â  Â  Â  Â  Â  Â  Â  "reportedCurrency": report.get("reportedCurrency", "USD"),
Â  Â  Â  Â  Â  Â  Â  Â  "type": "report"
Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  return reports, None
Â  Â  except Exception as e:
Â  Â  Â  Â  error_msg = f"Error fetching Financial Modeling Prep report: {str(e)}"
Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  return [], error_msg

# Fetch news or reports from the selected API
def fetch_news(selected_api, query="Iran", max_records=20, from_date=None, to_date=None):
Â  Â  st.write(f"Starting fetch process from {selected_api}...")
Â  Â  logger.info(f"Fetching from {selected_api} for query: {query}, max_records: {max_records}, from_date: {from_date}, to_date: {to_date}")

Â  Â  all_items = []
Â  Â  errors = []

Â  Â  api_functions = {
Â  Â  Â  Â  "GNews": fetch_gnews,
Â  Â  Â  Â  "World News API": fetch_worldnews,
Â  Â  Â  Â  "CoinGecko (Crypto News)": fetch_coingecko_news,
Â  Â  Â  Â  "Financial Report (FMP)": fetch_financial_report
Â  Â  }

Â  Â  fetch_function = api_functions.get(selected_api)
Â  Â  if not fetch_function:
Â  Â  Â  Â  error_msg = f"Invalid API selected: {selected_api}"
Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  st.error(error_msg)
Â  Â  Â  Â  return []

Â  Â  try:
Â  Â  Â  Â  fetch_query = query if selected_api != "Financial Report (FMP)" else query.upper()
Â  Â  Â  Â  items, error = fetch_function(fetch_query, max_records, from_date, to_date)
Â  Â  Â  Â  st.write(f"Fetched {len(items)} items from {selected_api}")
Â  Â  Â  Â  logger.info(f"Fetched {len(items)} items from {selected_api}")
Â  Â  Â  Â  if items:
Â  Â  Â  Â  Â  Â  all_items.extend(items)
Â  Â  Â  Â  if error:
Â  Â  Â  Â  Â  Â  errors.append(f"{selected_api}: {error}")
Â  Â  except Exception as e:
Â  Â  Â  Â  error_msg = f"Error fetching from {selected_api}: {str(e)}"
Â  Â  Â  Â  errors.append(error_msg)
Â  Â  Â  Â  st.error(error_msg)
Â  Â  Â  Â  send_error_email(error_msg)

Â  Â  if selected_api != "Financial Report (FMP)":
Â  Â  Â  Â  seen_urls = set()
Â  Â  Â  Â  unique_items = []
Â  Â  Â  Â  for item in all_items:
Â  Â  Â  Â  Â  Â  if item["url"] not in seen_urls:
Â  Â  Â  Â  Â  Â  Â  Â  seen_urls.add(item["url"])
Â  Â  Â  Â  Â  Â  Â  Â  unique_items.append(item)
Â  Â  Â  Â  all_items = unique_items[:max_records]
Â  Â  else:
Â  Â  Â  Â  all_items = all_items[:max_records]

Â  Â  logger.info(f"After processing: {len(all_items)} items")

Â  Â  for error in errors:
Â  Â  Â  Â  st.error(error)
Â  Â  Â  Â  send_error_email(error)

Â  Â  if all_items:
Â  Â  Â  Â  st.write(f"Successfully fetched {len(all_items)} items from {selected_api}!")
Â  Â  else:
Â  Â  Â  Â  st.warning(f"No items fetched from {selected_api}. This might be due to API indexing delays or invalid query. Try adjusting the date range or query.")

Â  Â  return all_items

# Function to translate text using Avalai API with /chat/completions
def translate_with_avalai(text, source_lang="en", target_lang="fa", avalai_api_url=AVALAI_API_URL_DEFAULT):
Â  Â  if not text:
Â  Â  Â  Â  logger.warning("Empty text provided for translation")
Â  Â  Â  Â  return text

Â  Â  if not AVALAI_API_KEY or AVALAI_API_KEY == "YOUR_AVALAI_API_KEY":
Â  Â  Â  Â  error_msg = "Invalid Avalai API key. Please set a valid API key in Render environment variables."
Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  return text

Â  Â  endpoint = f"{avalai_api_url}/chat/completions"
Â  Â  headers = {
Â  Â  Â  Â  "Authorization": f"Bearer {AVALAI_API_KEY}",
Â  Â  Â  Â  "Content-Type": "application/json",
Â  Â  Â  Â  "User-Agent": f"IranNewsAggregator/1.0 (Contact: avestaparsavic@gmail.com)"
Â  Â  }
Â  Â  payload = {
Â  Â  Â  Â  "model": "gpt-4.1-nano", # Using a potentially faster/cheaper model for translation
Â  Â  Â  Â  "messages": [
Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  "role": "system",
Â  Â  Â  Â  Â  Â  Â  Â  "content": f"You are a helpful translator. Translate the following text from {source_lang} to {target_lang}."
Â  Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  Â  {
Â  Â  Â  Â  Â  Â  Â  Â  "role": "user",
Â  Â  Â  Â  Â  Â  Â  Â  "content": text
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  ],
Â  Â  Â  Â  "max_tokens": 1000 # Limit response length for translation
Â  Â  }

Â  Â  try:
Â  Â  Â  Â  logger.info(f"Sending translation request to Avalai endpoint: {endpoint}")
Â  Â  Â  Â  response = requests.post(endpoint, headers=headers, json=payload, timeout=20) # Increased timeout
Â  Â  Â  Â  response.raise_for_status()
Â  Â  Â  Â  data = response.json()
Â  Â  Â  Â  logger.info(f"Avalai API response status: {response.status_code}")
Â  Â  Â  Â  logger.debug(f"Avalai API full response: {data}")

Â  Â  Â  Â  if "choices" in data and len(data["choices"]) > 0:
Â  Â  Â  Â  Â  Â  translated_text = data["choices"][0]["message"]["content"].strip()
Â  Â  Â  Â  Â  Â  logger.info(f"Translation successful. Translated text snippet: {translated_text[:50]}...")
Â  Â  Â  Â  Â  Â  return translated_text
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  error_msg = f"Avalai API response missing choices or choices is empty: {data}"
Â  Â  Â  Â  Â  Â  logger.warning(error_msg)
Â  Â  Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  Â  Â  return text # Return original text if translation fails
Â  Â  except requests.exceptions.RequestException as e:
Â  Â  Â  Â  error_msg = f"Network or API error during Avalai translation: {str(e)}"
Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  return text # Return original text on error
Â  Â  except Exception as e:
Â  Â  Â  Â  error_msg = f"Unexpected error during Avalai translation: {str(e)}"
Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  return text # Return original text on error


# Function to convert UTC time to Tehran time and return as datetime object
def parse_to_tehran_time(utc_time_str):
Â  Â  if not utc_time_str:
Â  Â  Â  Â  logger.warning("Empty time string provided")
Â  Â  Â  Â  return None

Â  Â  time_formats = [
Â  Â  Â  Â  "%Y-%m-%dT%H:%M:%SZ", # GNews
Â  Â  Â  Â  "%Y-%m-%d %H:%M:%S", # World News API (sometimes)
Â  Â  Â  Â  "%Y-%m-%dT%H:%M:%S", # World News API (sometimes)
Â  Â  Â  Â  "%Y-%m-%dT%H:%M:%S.%fZ", # GNews (sometimes)
Â  Â  Â  Â  "%Y-%m-%d %H:%M:%S.%f",
Â  Â  Â  Â  "%Y-%m-%dT%H:%M:%S%z",
Â  Â  Â  Â  "%Y-%m-%dT%H:%M:%S.%f%z",
Â  Â  Â  Â  "%Y-%m-%d",Â  # For financial reports (just date) or APIs with only date
Â  Â  Â  Â  "%Y-%m-%dT%H:%M:%S+00:00", # CoinGecko
Â  Â  ]

Â  Â  utc_time = None
Â  Â  for time_format in time_formats:
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  # Handle timezone info if present
Â  Â  Â  Â  Â  Â  if '%' in time_format and 'z' in time_format:
Â  Â  Â  Â  Â  Â  Â  Â  utc_time = datetime.strptime(utc_time_str, time_format)
Â  Â  Â  Â  Â  Â  Â  Â  # Convert to UTC if a timezone is parsed
Â  Â  Â  Â  Â  Â  Â  Â  if utc_time.tzinfo is not None:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  import pytz
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  utc_time = utc_time.astimezone(pytz.utc).replace(tzinfo=None)
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  utc_time = datetime.strptime(utc_time_str, time_format)

Â  Â  Â  Â  Â  Â  # If only date is parsed, assume midnight UTC
Â  Â  Â  Â  Â  Â  if len(utc_time_str.split('T')) == 1 and '-' in utc_time_str and ':' not in utc_time_str:
Â  Â  Â  Â  Â  Â  Â  Â  utc_time = datetime.strptime(utc_time_str, "%Y-%m-%d")

Â  Â  Â  Â  Â  Â  tehran_time = utc_time + timedelta(hours=3, minutes=30)
Â  Â  Â  Â  Â  Â  logger.info(f"Successfully parsed time: {utc_time_str} -> {tehran_time} (Tehran Time)")
Â  Â  Â  Â  Â  Â  return tehran_time
Â  Â  Â  Â  except ValueError:
Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  logger.error(f"Unexpected error parsing time {utc_time_str} with format {time_format}: {str(e)}")
Â  Â  Â  Â  Â  Â  continue

Â  Â  error_msg = f"Error converting time: Invalid format or parsing error - Input: {utc_time_str}"
Â  Â  logger.warning(error_msg)
Â  Â  send_error_email(error_msg)
Â  Â  return None


# Function to format Tehran time for display
def format_tehran_time(tehran_time):
Â  Â  if not isinstance(tehran_time, datetime):
Â  Â  Â  Â  logger.warning(f"Invalid input for format_tehran_time: {tehran_time}")
Â  Â  Â  Â  return str(tehran_time) # Return as is if not a datetime object
Â  Â  return tehran_time.strftime("%Y/%m/%d - %H:%M")

# Function to truncate text to a specified length
def truncate_text(text, max_length=100):
Â  Â  if not isinstance(text, str):
Â  Â  Â  Â  return str(text)
Â  Â  if len(text) > max_length:
Â  Â  Â  Â  return text[:max_length].rsplit(" ", 1)[0] + "..."
Â  Â  return text

# Function to extract article content for Instant View (Simplified)
def extract_article_content(url):
Â  Â  try:
Â  Â  Â  Â  headers = {
Â  Â  Â  Â  Â  Â  "User-Agent": f"IranNewsAggregator/1.0 (Contact: avestaparsavic@gmail.com)"
Â  Â  Â  Â  }
Â  Â  Â  Â  logger.info(f"Attempting to extract content from: {url}")
Â  Â  Â  Â  response = requests.get(url, headers=headers, timeout=15)
Â  Â  Â  Â  response.raise_for_status()

Â  Â  Â  Â  soup = BeautifulSoup(response.text, 'html.parser')

Â  Â  Â  Â  # Attempt to find common article content containers
Â  Â  Â  Â  possible_containers = [
Â  Â  Â  Â  Â  Â  'article',
Â  Â  Â  Â  Â  Â  '.article-content',
Â  Â  Â  Â  Â  Â  '.entry-content',
Â  Â  Â  Â  Â  Â  '.post-content',
Â  Â  Â  Â  Â  Â  '.story-body',
Â  Â  Â  Â  Â  Â  'main',
Â  Â  Â  Â  Â  Â  'body' # Fallback
Â  Â  Â  Â  ]

Â  Â  Â  Â  content_element = None
Â  Â  Â  Â  for selector in possible_containers:
Â  Â  Â  Â  Â  Â  content_element = soup.select_one(selector)
Â  Â  Â  Â  Â  Â  if content_element:
Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  content = ""
Â  Â  Â  Â  if content_element:
Â  Â  Â  Â  Â  Â  paragraphs = content_element.find_all('p')
Â  Â  Â  Â  Â  Â  content = " ".join([para.get_text(strip=True) for para in paragraphs if para.get_text(strip=True)])
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  # If no specific container found, just get all paragraphs in the body
Â  Â  Â  Â  Â  Â  paragraphs = soup.find_all('p')
Â  Â  Â  Â  Â  Â  content = " ".join([para.get_text(strip=True) for para in paragraphs if para.get_text(strip=True)])


Â  Â  Â  Â  if not content or len(content.split()) < 20: # Minimum word count check
Â  Â  Â  Â  Â  Â  logger.warning(f"Insufficient content extracted from URL: {url}. Length: {len(content)}")
Â  Â  Â  Â  Â  Â  return "No significant content available or extraction failed."

Â  Â  Â  Â  # Basic cleaning
Â  Â  Â  Â  content = content.replace('\n', ' ').strip()
Â  Â  Â  Â  content = ' '.join(content.split()) # Remove multiple spaces

Â  Â  Â  Â  logger.info(f"Extracted content (length: {len(content)}): {content[:200]}...")
Â  Â  Â  Â  return content
Â  Â  except Exception as e:
Â  Â  Â  Â  error_msg = f"Error extracting content from {url}: {str(e)}"
Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  return "Unable to extract content."


# Function to filter items by time range (for news only)
def filter_articles_by_time(items, time_range_hours, start_date=None, end_date=None, disable_filter=False):
Â  Â  if not items:
Â  Â  Â  Â  return []

Â  Â  # Do not filter financial reports by time range
Â  Â  if items and items[0].get("type") == "report":
Â  Â  Â  Â  return items

Â  Â  if disable_filter:
Â  Â  Â  Â  logger.info("Time filter disabled. Returning all articles.")
Â  Â  Â  Â  return items

Â  Â  filtered_items = []
Â  Â  current_utc_time = datetime.utcnow()
Â  Â  tehran_timezone_offset = timedelta(hours=3, minutes=30)
Â  Â  current_tehran_time = current_utc_time + tehran_timezone_offset

Â  Â  if time_range_hours == float("inf"): # Custom date range
Â  Â  Â  Â  if start_date and end_date:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  # Convert start/end dates (from UI) to datetime objects for comparison
Â  Â  Â  Â  Â  Â  Â  Â  # Note: parse_to_tehran_time now returns Tehran time. We compare Tehran times.
Â  Â  Â  Â  Â  Â  Â  Â  start_datetime_tehran = datetime.combine(start_date, datetime.min.time()) + tehran_timezone_offset
Â  Â  Â  Â  Â  Â  Â  Â  end_datetime_tehran = datetime.combine(end_date, datetime.max.time()) + tehran_timezone_offset

Â  Â  Â  Â  Â  Â  Â  Â  for item in items:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  published_time_tehran = parse_to_tehran_time(item["published_at"]) # Already Tehran time

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if published_time_tehran:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logger.info(f"Article Tehran time: {published_time_tehran}, Start Tehran: {start_datetime_tehran}, End Tehran: {end_datetime_tehran}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if start_datetime_tehran <= published_time_tehran <= end_datetime_tehran:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  filtered_items.append(item)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logger.warning(f"Skipping article due to unparseable time: {item['published_at']}")
Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  logger.error(f"Error filtering by custom date range: {str(e)}")
Â  Â  Â  Â  Â  Â  Â  Â  send_error_email(f"Error filtering by custom date range: {str(e)}")
Â  Â  Â  Â  Â  Â  Â  Â  # If filtering fails, return all items to be safe
Â  Â  Â  Â  Â  Â  Â  Â  return items
Â  Â  else: # Relative time range
Â  Â  Â  Â  cutoff_time_tehran = current_tehran_time - timedelta(hours=time_range_hours)
Â  Â  Â  Â  for item in items:
Â  Â  Â  Â  Â  Â  published_time_tehran = parse_to_tehran_time(item["published_at"])
Â  Â  Â  Â  Â  Â  if published_time_tehran:
Â  Â  Â  Â  Â  Â  Â  Â  logger.info(f"Article Tehran time: {published_time_tehran}, Cutoff Tehran time: {cutoff_time_tehran}")
Â  Â  Â  Â  Â  Â  Â  Â  if published_time_tehran >= cutoff_time_tehran:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  filtered_items.append(item)
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  logger.warning(f"Skipping article due to unparseable time: {item['published_at']}")

Â  Â  logger.info(f"After filtering: {len(filtered_items)} items remain out of {len(items)}")
Â  Â  return filtered_items


# Function to pre-process articles (translations only, skip for reports)
def pre_process_articles(items, avalai_api_url, enable_translation=False, num_items_to_translate=1):
Â  Â  if not items:
Â  Â  Â  Â  return items

Â  Â  # Do not translate financial reports
Â  Â  if items and items[0].get("type") == "report":
Â  Â  Â  Â  return items

Â  Â  # Sort items by date before translating the latest ones
Â  Â  sorted_items = sorted(
Â  Â  Â  Â  items,
Â  Â  Â  Â  key=lambda x: parse_to_tehran_time(x["published_at"]) or datetime.min,
Â  Â  Â  Â  reverse=True
Â  Â  )
Â  Â  logger.info(f"Sorted {len(sorted_items)} items for translation processing")

Â  Â  processed_items = []
Â  Â  for i, item in enumerate(sorted_items):
Â  Â  Â  Â  processed_item = item.copy() # Work on a copy to avoid modifying original list during iteration

Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  if enable_translation and i < num_items_to_translate:
Â  Â  Â  Â  Â  Â  Â  Â  logger.info(f"Translating item {i+1}: {processed_item['title']}")
Â  Â  Â  Â  Â  Â  Â  Â  translated_title = translate_with_avalai(processed_item["title"], source_lang="en", target_lang="fa", avalai_api_url=avalai_api_url)
Â  Â  Â  Â  Â  Â  Â  Â  logger.info(f"Translated title for item {i+1}: {translated_title[:50]}...")
Â  Â  Â  Â  Â  Â  Â  Â  processed_item["translated_title"] = translated_title

Â  Â  Â  Â  Â  Â  Â  Â  translated_description = translate_with_avalai(processed_item["description"], source_lang="en", target_lang="fa", avalai_api_url=avalai_api_url)
Â  Â  Â  Â  Â  Â  Â  Â  logger.info(f"Translated description for item {i+1}: {translated_description[:50]}...")
Â  Â  Â  Â  Â  Â  Â  Â  processed_item["translated_description"] = translated_description

Â  Â  Â  Â  Â  Â  Â  Â  if translated_description == processed_item["description"] and processed_item["description"]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # This check might be too simple, as a short text might translate to itself
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Consider adding a more robust check or just log a warning.
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logger.info(f"Translation for description of item {i+1} returned original text.")
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  processed_item["translated_title"] = processed_item["title"]
Â  Â  Â  Â  Â  Â  Â  Â  processed_item["translated_description"] = processed_item["description"]
Â  Â  Â  Â  Â  Â  Â  Â  if enable_translation and i >= num_items_to_translate:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logger.info(f"Skipping translation for item {i+1}: {processed_item['title']} (beyond limit of {num_items_to_translate})")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # st.info(f"Item {i+1} ({processed_item['title']}) skipped for translation (beyond limit of {num_items_to_translate})")

Â  Â  Â  Â  Â  Â  processed_items.append(processed_item)

Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  st.error(f"Error processing item {processed_item.get('title', 'Unknown Title')}: {str(e)}")
Â  Â  Â  Â  Â  Â  logger.error(f"Error in pre_process_articles for item {processed_item.get('title', 'Unknown Title')}: {str(e)}")
Â  Â  Â  Â  Â  Â  send_error_email(f"Error in pre_process_articles: {str(e)} - Item: {processed_item.get('title', 'Unknown Title')}")
Â  Â  Â  Â  Â  Â  processed_items.append(processed_item) # Append original item if processing fails

Â  Â  return processed_items


# Function to display items (news or reports) in a nice format
def display_items(items):
Â  Â  st.write(f"Attempting to display {len(items)} items...")
Â  Â  logger.info(f"Displaying {len(items)} items")

Â  Â  if not items:
Â  Â  Â  Â  st.warning("No items to display. This might be due to filtering or no items being fetched.")
Â  Â  Â  Â  return

Â  Â  item_type = items[0].get("type", "news")

Â  Â  if item_type == "news":
Â  Â  Â  Â  sorted_items = sorted(
Â  Â  Â  Â  Â  Â  items,
Â  Â  Â  Â  Â  Â  key=lambda x: parse_to_tehran_time(x["published_at"]) or datetime.min,
Â  Â  Â  Â  Â  Â  reverse=True
Â  Â  Â  Â  )
Â  Â  Â  Â  logger.info(f"Sorted articles: {len(sorted_items)} articles after sorting")

Â  Â  Â  Â  st.subheader("News Statistics")
Â  Â  Â  Â  if sorted_items:
Â  Â  Â  Â  Â  Â  sources = pd.DataFrame([item["source"] for item in sorted_items]).value_counts().reset_index()
Â  Â  Â  Â  Â  Â  sources.columns = ["Source", "Count"]
Â  Â  Â  Â  Â  Â  if len(sources) > 1:
Â  Â  Â  Â  Â  Â  Â  Â  col1, col2 = st.columns(2)
Â  Â  Â  Â  Â  Â  Â  Â  with col1:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.bar_chart(sources.set_index("Source"))
Â  Â  Â  Â  Â  Â  Â  Â  with col2:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(sources)
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"All articles from: {sources.iloc[0, 0]}")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.info("No news items to display statistics.")


Â  Â  Â  Â  st.subheader("Selected Articles")
Â  Â  Â  Â  # Use item URL as a unique identifier for selection state
Â  Â  Â  Â  selected_urls = {a.get('url') for a in st.session_state.selected_items}
Â  Â  Â  Â  selected_count = len(selected_urls)
Â  Â  Â  Â  st.write(f"You have selected {selected_count} article(s) to send to Telegram")
Â  Â  Â  Â  logger.info(f"Current selected items (by URL): {selected_urls}")


Â  Â  Â  Â  st.subheader("News Articles")
Â  Â  Â  Â  col1, col2 = st.columns(2)
Â  Â  Â  Â  for i, item in enumerate(sorted_items):
Â  Â  Â  Â  Â  Â  current_col = col1 if i % 2 == 0 else col2

Â  Â  Â  Â  Â  Â  with current_col:
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f'<div class="neon-line-top"></div>', unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  logger.info(f"Rendering article {i+1}: {item['title']}")

Â  Â  Â  Â  Â  Â  Â  Â  item_url = item.get('url')
Â  Â  Â  Â  Â  Â  Â  Â  is_selected = item_url in selected_urls
Â  Â  Â  Â  Â  Â  Â  Â  checkbox_key = f"article_select_{item_url}_{i}" # Unique key including URL and index

Â  Â  Â  Â  Â  Â  Â  Â  if st.checkbox("Select for Telegram", key=checkbox_key, value=is_selected):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not is_selected:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.selected_items.append(item)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logger.info(f"Added article to selected: {item['title']}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Update the selected_urls set immediately
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  selected_urls.add(item_url)
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if is_selected:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Remove the item based on URL
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.selected_items = [a for a in st.session_state.selected_items if a.get('url') != item_url]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logger.info(f"Removed article from selected: {item['title']}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Update the selected_urls set immediately
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  selected_urls.discard(item_url)

Â  Â  Â  Â  Â  Â  Â  Â  tehran_time = parse_to_tehran_time(item["published_at"])
Â  Â  Â  Â  Â  Â  Â  Â  tehran_time_str = format_tehran_time(tehran_time) if tehran_time else item["published_at"]
Â  Â  Â  Â  Â  Â  Â  Â  truncated_description = truncate_text(item["description"], max_length=200) # Increased description truncate
Â  Â  Â  Â  Â  Â  Â  Â  truncated_translated_description = truncate_text(item["translated_description"], max_length=200) # Increased description truncate

Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f'<div class="article-section">', unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f'<h3 class="title-link"><a href="{item["url"]}" target="_blank">{item["translated_title"]}</a></h3>', unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f'<div class="source-date">**Source:** {item["source"]} | **Ø§Ù†ØªØ´Ø§Ø±:** {tehran_time_str}</div>', unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  if item["image_url"]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Add a caption or descriptive text for the image if available
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.image(item["image_url"], width=300, caption=item.get("title", "Article Image"))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logger.warning(f"Could not load image from {item['image_url']}: {str(e)}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("Image could not be loaded")
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f'<div class="english-text description">**Description (English):** {truncated_description}</div>', unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f'<div class="persian-text description">**ØªÙˆØ¶ÛŒØ­Ø§Øª (ÙØ§Ø±Ø³ÛŒ):** {truncated_translated_description}</div>', unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown('</div>', unsafe_allow_html=True)
Â  Â  else: # Financial Reports
Â  Â  Â  Â  st.subheader("Financial Reports")
Â  Â  Â  Â  for i, report in enumerate(items):
Â  Â  Â  Â  Â  Â  st.markdown(f'<div class="report-section">', unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  st.markdown(f"**Ù†Ù…Ø§Ø¯ Ø´Ø±Ú©Øª:** {report['symbol']}", unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  st.markdown(f"**ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´:** {report['date']}", unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  st.markdown(f"**Ø§Ø±Ø² Ú¯Ø²Ø§Ø±Ø´:** {report['reportedCurrency']}", unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  st.markdown(f"**Ø¯Ø±Ø¢Ù…Ø¯:** {report['revenue']:,} {report['reportedCurrency']}", unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  st.markdown(f"**Ø³ÙˆØ¯ Ø®Ø§Ù„Øµ:** {report['netIncome']:,} {report['reportedCurrency']}", unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  st.markdown(f"**Ø³ÙˆØ¯ Ù‡Ø± Ø³Ù‡Ù… (EPS):** {report['eps']}", unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  st.markdown(f"**Ø³ÙˆØ¯ Ù†Ø§Ø®Ø§Ù„Øµ:** {report['grossProfit']:,} {report['reportedCurrency']}", unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  st.markdown(f"**Ø¯Ø±Ø¢Ù…Ø¯ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ:** {report['operatingIncome']:,} {report['reportedCurrency']}", unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  st.markdown('</div>', unsafe_allow_html=True)

# Function to save items to a file for download
def save_items_to_file_for_download(items, format="csv"):
Â  Â  if not items:
Â  Â  Â  Â  return None
Â  Â  df = pd.DataFrame(items)
Â  Â  if format == "csv":
Â  Â  Â  Â  buffer = BytesIO()
Â  Â  Â  Â  df.to_csv(buffer, index=False)
Â  Â  Â  Â  return buffer.getvalue()
Â  Â  elif format == "json":
Â  Â  Â  Â  return json.dumps(items, indent=2, ensure_ascii=False).encode('utf-8') # Ensure proper encoding
Â  Â  return None

# Function to send a message to Telegram (include title, description, time, and Instant View for news; financial data for reports)
def send_telegram_message(chat_id, message, disable_web_page_preview=False):
Â  Â  if not TELEGRAM_BOT_TOKEN or TELEGRAM_BOT_TOKEN == "YOUR_TELEGRAM_BOT_TOKEN":
Â  Â  Â  Â  error_msg = "Telegram bot token is not set. Cannot send messages."
Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  st.error(error_msg)
Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  return False

Â  Â  try:
Â  Â  Â  Â  # Telegram message limit is 4096 characters. Split into multiple messages if needed.
Â  Â  Â  Â  max_chars = 4000 # Keep a buffer
Â  Â  Â  Â  messages_to_send = [message[i:i + max_chars] for i in range(0, len(message), max_chars)]

Â  Â  Â  Â  success = True
Â  Â  Â  Â  for msg_part in messages_to_send:
Â  Â  Â  Â  Â  Â  url = f"{TELEGRAM_API_URL}/sendMessage"
Â  Â  Â  Â  Â  Â  data = {
Â  Â  Â  Â  Â  Â  Â  Â  "chat_id": chat_id,
Â  Â  Â  Â  Â  Â  Â  Â  "text": msg_part,
Â  Â  Â  Â  Â  Â  Â  Â  "parse_mode": "Markdown",
Â  Â  Â  Â  Â  Â  Â  Â  "disable_web_page_preview": disable_web_page_preview
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  logger.info(f"Sending message to chat ID {chat_id}: {msg_part[:100]}...")

Â  Â  Â  Â  Â  Â  response = requests.post(url, json=data, timeout=10)
Â  Â  Â  Â  Â  Â  response_data = response.json()
Â  Â  Â  Â  Â  Â  logger.info(f"Telegram API response for sendMessage: {response_data}")

Â  Â  Â  Â  Â  Â  if response.status_code != 200 or not response_data.get("ok"):
Â  Â  Â  Â  Â  Â  Â  Â  error_msg = f"Error sending message to Telegram chat ID {chat_id}: {response_data.get('description', 'Unknown error')}"
Â  Â  Â  Â  Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  Â  Â  Â  Â  st.error(error_msg)
Â  Â  Â  Â  Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  Â  Â  Â  Â  success = False # Mark as failed but try sending other parts

Â  Â  Â  Â  return success

Â  Â  except Exception as e:
Â  Â  Â  Â  error_msg = f"Exception during Telegram message sending to chat ID {chat_id}: {str(e)}"
Â  Â  Â  Â  logger.error(error_msg)
Â  Â  Â  Â  st.error(error_msg)
Â  Â  Â  Â  send_error_email(error_msg)
Â  Â  Â  Â  return False


# --- Streamlit App Layout ---

st.title("Iran News and Financial Report Aggregator")

# Sidebar for API keys, settings, and Telegram
with st.sidebar:
Â  Â  st.header("Configuration")

Â  Â  st.warning("API keys are read from environment variables. If you see 'YOUR_API_KEY' placeholders, please set the environment variables (GNEWS_API_KEY, WORLDNEWS_API_KEY, FMP_API_KEY, AVALAI_API_KEY, TELEGRAM_BOT_TOKEN) on your hosting platform (e.g., Render.com).")

Â  Â  st.header("Data Sources")
Â  Â  selected_api = st.selectbox(
Â  Â  Â  Â  "Select API:",
Â  Â  Â  Â  ["GNews", "World News API", "CoinGecko (Crypto News)", "Financial Report (FMP)"]
Â  Â  )

Â  Â  query = st.text_input(
Â  Â  Â  Â  f"Enter Query/Symbol for {selected_api}:",
Â  Â  Â  Â  value="Iran" if selected_api != "Financial Report (FMP)" else "AAPL" # Default query
Â  Â  )

Â  Â  max_records = st.slider(
Â  Â  Â  Â  "Maximum number of records:",
Â  Â  Â  Â  min_value=1,
Â  Â  Â  Â  max_value=100,
Â  Â  Â  Â  value=20,
Â  Â  Â  Â  step=1
Â  Â  )

Â  Â  st.header("Time Filtering")
Â  Â  time_filter_option = st.radio(
Â  Â  Â  Â  "Select time range:",
Â  Â  Â  Â  ["Last Hour", "Last 24 Hours", "Last 7 Days", "Custom Date Range", "Disable Filter"]
Â  Â  )

Â  Â  from_date, to_date = None, None
Â  Â  date_range = None # Initialize date_range to None
Â  Â  if time_filter_option == "Custom Date Range":
Â  Â  Â  Â  # Ensure date_input always returns a tuple, even if only one date is selected initially
Â  Â  Â  Â  date_range_input = st.date_input("Select date range", value=(datetime.now() - timedelta(days=7)).date(), key='date_range')
Â  Â  Â  Â  if isinstance(date_range_input, tuple) and len(date_range_input) == 2:
Â  Â  Â  Â  Â  Â  date_range = date_range_input
Â  Â  Â  Â  Â  Â  from_date = date_range[0].strftime("%Y-%m-%d")
Â  Â  Â  Â  Â  Â  to_date = date_range[1].strftime("%Y-%m-%d")
Â  Â  Â  Â  elif isinstance(date_range_input, datetime):
Â  Â  Â  Â  Â  Â  date_range = (date_range_input, date_range_input) # Treat single date as a range
Â  Â  Â  Â  Â  Â  from_date = date_range[0].strftime("%Y-%m-%d")
Â  Â  Â  Â  Â  Â  to_date = date_range[1].strftime("%Y-%m-%d")


Â  Â  Â  Â  logger.info(f"Custom date range selected: From {from_date} to {to_date}")
Â  Â  else:
Â  Â  Â  Â  from_date, to_date = None, None # Reset date range inputs if not in custom mode
Â  Â  Â  Â  date_range = None


Â  Â  time_range_hours = {
Â  Â  Â  Â  "Last Hour": 1,
Â  Â  Â  Â  "Last 24 Hours": 24,
Â  Â  Â  Â  "Last 7 Days": 7 * 24,
Â  Â  Â  Â  "Custom Date Range": float("inf"), # Use infinity to indicate custom date range
Â  Â  Â  Â  "Disable Filter": None # None indicates no time filter
Â  Â  }.get(time_filter_option)

Â  Â  disable_time_filter = (time_filter_option == "Disable Filter")

Â  Â  st.header("Translation Settings (News Only)")
Â  Â  enable_translation = st.checkbox("Enable Translation (English to Persian)", value=False)
Â  Â  num_items_to_translate = st.slider(
Â  Â  Â  Â  "Number of latest items to translate:",
Â  Â  Â  Â  min_value=0,
Â  Â  Â  Â  max_value=max_records,
Â  Â  Â  Â  value=1,
Â  Â  Â  Â  step=1,
Â  Â  Â  Â  disabled=not enable_translation
Â  Â  )
Â  Â  avalai_api_url = st.text_input("Avalai API URL", value=AVALAI_API_URL_DEFAULT, disabled=not enable_translation)


Â  Â  st.header("Telegram Settings")
Â  Â  chat_ids = load_chat_ids()
Â  Â  current_chat_id = chat_ids.get("default_chat_id", "")
Â  Â  telegram_chat_id = st.text_input("Telegram Chat ID (e.g., -1001234567890)", value=current_chat_id)

Â  Â  # Save chat ID when input changes
Â  Â  if telegram_chat_id and telegram_chat_id != current_chat_id:
Â  Â  Â  Â  chat_ids["default_chat_id"] = telegram_chat_id
Â  Â  Â  Â  save_chat_ids(chat_ids)
Â  Â  Â  Â  logger.info(f"Saved default Telegram Chat ID: {telegram_chat_id}")


# --- Main Content Area ---

if 'fetched_items' not in st.session_state:
Â  Â  st.session_state.fetched_items = []

if 'selected_items' not in st.session_state:
Â  Â  st.session_state.selected_items = []

# Fetch Button
if st.button(f"Fetch from {selected_api}"):
Â  Â  st.session_state.selected_items = [] # Clear selected items on new fetch
Â  Â  with st.spinner(f"Fetching data from {selected_api}..."):
Â  Â  Â  Â  fetched_items = fetch_news(selected_api, query, from_date=from_date, to_date=to_date, max_records=max_records) # Pass dates and max_records to fetch_news

Â  Â  Â  Â  if selected_api != "Financial Report (FMP)":
Â  Â  Â  Â  Â  Â  # Apply time filter before translation and display for news
Â  Â  Â  Â  Â  Â  filtered_items = filter_articles_by_time(fetched_items, time_range_hours, date_range[0] if time_filter_option == "Custom Date Range" and date_range else None, date_range[1] if time_filter_option == "Custom Date Range" and date_range else None, disable_time_filter)
Â  Â  Â  Â  Â  Â  # Pre-process (translate) filtered news items
Â  Â  Â  Â  Â  Â  processed_items = pre_process_articles(filtered_items, avalai_api_url, enable_translation, num_items_to_translate)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  # No time filter or translation for financial reports displayed here, they are filtered by date in fetch_financial_report
Â  Â  Â  Â  Â  Â  processed_items = fetched_items # Financial reports are already filtered by date in fetch_financial_report if dates are provided

Â  Â  Â  Â  st.session_state.fetched_items = processed_items # Store processed items
Â  Â  Â  Â  # Corrected line: Check the length of fetched_items, not a non-existent 'items'
Â  Â  Â  Â  st.info(f"Found {len(st.session_state.fetched_items)} items in session state!")


# Display fetched items
if st.session_state.fetched_items:
Â  Â  display_items(st.session_state.fetched_items)

# Send to Telegram Button
if st.session_state.selected_items:
Â  Â  st.subheader("Send to Telegram")
Â  Â  if not telegram_chat_id:
Â  Â  Â  Â  st.warning("Please enter a Telegram Chat ID in the sidebar to send messages.")
Â  Â  elif st.button(f"Send {len(st.session_state.selected_items)} Selected Item(s) to Telegram"):
Â  Â  Â  Â  with st.spinner(f"Sending {len(st.session_state.selected_items)} item(s) to Telegram..."):
Â  Â  Â  Â  Â  Â  all_successful = True
Â  Â  Â  Â  Â  Â  for item in st.session_state.selected_items:
Â  Â  Â  Â  Â  Â  Â  Â  if item["type"] == "news":
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tehran_time = parse_to_tehran_time(item["published_at"])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tehran_time_str = format_tehran_time(tehran_time) if tehran_time else item["published_at"]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Consider extracting full content for Telegram message if needed
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # extracted_content = extract_article_content(item["url"])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # message = f"*{item['translated_title']}*\n\nSource: {item['source']} | Published: {tehran_time_str}\n\n{extracted_content}\n\n[Read More]({item['url']})"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Using the translated description and linking to the original article
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  message = f"*{item['translated_title']}*\n\n**Ù…Ù†Ø¨Ø¹:** {item['source']} | **Ø§Ù†ØªØ´Ø§Ø±:** {tehran_time_str}\n\n{item['translated_description']}\n\n[Read More]({item['url']})"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Disable web page preview for news articles to avoid duplicate display in Telegram
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not send_telegram_message(telegram_chat_id, message, disable_web_page_preview=True):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_successful = False
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logger.error(f"Failed to send article: {item['title']}")
Â  Â  Â  Â  Â  Â  Â  Â  else: # Financial Reports
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  message = f"**Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù„ÛŒ:** {item['symbol']}\n\n**ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´:** {item['date']}\n**Ø§Ø±Ø² Ú¯Ø²Ø§Ø±Ø´:** {item['reportedCurrency']}\n**Ø¯Ø±Ø¢Ù…Ø¯:** {item['revenue']:,} {item['reportedCurrency']}\n**Ø³ÙˆØ¯ Ø®Ø§Ù„Øµ:** {item['netIncome']:,} {item['reportedCurrency']}\n**Ø³ÙˆØ¯ Ù‡Ø± Ø³Ù‡Ù… (EPS):** {item['eps']}\n**Ø³ÙˆØ¯ Ù†Ø§Ø®Ø§Ù„Øµ:** {item['grossProfit']:,} {item['reportedCurrency']}\n**Ø¯Ø±Ø¢Ù…Ø¯ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ:** {item['operatingIncome']:,} {item['reportedCurrency']}"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not send_telegram_message(telegram_chat_id, message):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_successful = False
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logger.error(f"Failed to send report for symbol: {item['symbol']}")

Â  Â  Â  Â  Â  Â  Â  Â  time.sleep(0.5) # Add a small delay between sending messages

Â  Â  Â  Â  if all_successful:
Â  Â  Â  Â  Â  Â  st.success("Selected item(s) sent to Telegram successfully!")
Â  Â  Â  Â  Â  Â  # Optional: Clear selected items after sending
Â  Â  Â  Â  Â  Â  # st.session_state.selected_items = []
Â  Â  Â  Â  Â  Â  # st.rerun() # Rerun to update the UI and remove checkboxes
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.error("Some items failed to send to Telegram.")

# Download Button
if st.session_state.fetched_items:
Â  Â  st.subheader("Download Data")
Â  Â  download_format = st.selectbox("Select download format:", ["csv", "json"])
Â  Â  download_data = save_items_to_file_for_download(st.session_state.fetched_items, download_format)
Â  Â  if download_data is not None: # Check if download_data is not None
Â  Â  Â  Â  file_extension = download_format
Â  Â  Â  Â  mime_type = "text/csv" if download_format == "csv" else "application/json"
Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  label=f"Download Data as .{file_extension}",
Â  Â  Â  Â  Â  Â  data=download_data,
Â  Â  Â  Â  Â  Â  file_name=f"iran_news_and_reports.{file_extension}",
Â  Â  Â  Â  Â  Â  mime=mime_type,
Â  Â  Â  Â  )
Â  Â  else:
Â  Â  Â  Â  st.info("No data available to download.")


# Optional: Clear Fetched Items Button
if st.session_state.fetched_items or st.session_state.selected_items:
Â  Â  if st.button("Clear All Fetched and Selected Items"):
Â  Â  Â  Â  st.session_state.fetched_items = []
Â  Â  Â  Â  st.session_state.selected_items = []
Â  Â  Â  Â  # Optional: Clear the temporary file
Â  Â  Â  Â  # if os.path.exists(TEMP_FILE):
Â  Â  Â  Â  # Â  Â  os.remove(TEMP_FILE)
Â  Â  Â  Â  st.success("Cleared all fetched and selected items.")
Â  Â  Â  Â  st.rerun() # Rerun to update the UI


# Optional: Info about the app
st.markdown("---")
st.info("This app aggregates news and financial reports using various APIs. News articles can be translated to Persian and sent to a specified Telegram chat.")

st.markdown("Developed by [Your Name/Contact Info or GitHub Link]") # Replace with actual info
